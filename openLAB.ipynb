{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"openLAB.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1lA7dXrIyQmFUOTbl2uHbqgjfMLkBstk8","authorship_tag":"ABX9TyM0nUSJh3cNDgey05XhIaWO"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DBNpsooeGwjE","executionInfo":{"status":"ok","timestamp":1607164242029,"user_tz":-540,"elapsed":22893,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}},"outputId":"d040ca9d-13db-41ab-9dc3-364e87895709"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vrU31VYjHq10"},"source":["# !pip3 install http://download.pytorch.org/whl/cu80/torch-0.3.0.post4-cp36-cp36m-linux_x86_64.whl\n","# !pip3 install torchvision"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3AuJYGoeKKhU","executionInfo":{"status":"ok","timestamp":1607255771670,"user_tz":-540,"elapsed":40417,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}},"outputId":"7ec16f8f-77e5-4294-817d-090f58a18201"},"source":["!apt-get update !apt-get install g++ openjdk-8-jdk python-dev python3-dev\n","!pip3 install JPype1-py3 \n","!pip3 install konlpy \n","!JAVA_HOME=\"C:\\Program Files\\Java\\jdk1.8.0_271\"\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["E: The update command takes no arguments\n","Collecting JPype1-py3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/63f5e4202c598f362ee4684b41890f993d6e58309c5d90703f570ab85f62/JPype1-py3-0.5.5.4.tar.gz (88kB)\n","\u001b[K     |████████████████████████████████| 92kB 8.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: JPype1-py3\n","  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp36-cp36m-linux_x86_64.whl size=2679166 sha256=8a45467dde2b77fe028eb6743b7613069e17746a3101c0f8ced0e2dd644f9299\n","  Stored in directory: /root/.cache/pip/wheels/52/37/1f/1015d908d12a0e9b239543d031fda0cded9823aa1306939541\n","Successfully built JPype1-py3\n","Installing collected packages: JPype1-py3\n","Successfully installed JPype1-py3-0.5.5.4\n","Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 9.4MB/s \n","\u001b[?25hCollecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b7/21/9e2c0dbf9df856e6392a1aec1d18006c60b175aa4e31d351e8278a8a63c0/JPype1-1.2.0-cp36-cp36m-manylinux2010_x86_64.whl (453kB)\n","\u001b[K     |████████████████████████████████| 460kB 57.3MB/s \n","\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.11.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: colorama, tweepy, beautifulsoup4, JPype1, konlpy\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","Successfully installed JPype1-1.2.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2 tweepy-3.9.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99QcvKk9MC3Y","executionInfo":{"status":"ok","timestamp":1607258305254,"user_tz":-540,"elapsed":152943,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}},"outputId":"cf1882a9-c95f-4de4-b7de-4cdcffa33ce6"},"source":["import csv\n","import pandas as pd\n","import numpy as np\n","import torch\n","from konlpy.tag import Komoran\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from collections import defaultdict\n","\n","# 데이터 파트 안하셔도 되고 노션에서 데이터 다운로드하신 후에 맨아래 공통파트만 하시면 됩니다!\n","############하이퍼파라미터\n","#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","# 공통파트\n","# 데이터 전처리\n","csv.field_size_limit(100000000)\n","from torchtext import data\n","\n","tokenizer = Komoran()\n","#데이터 필드 정의\n","TEXT = data.Field(sequential=True,\n","                  use_vocab=True,\n","                  tokenize=tokenizer.morphs,\n","                  lower=True,\n","                  batch_first=True,\n","                  fix_length=60)\n","\n","LABEL = data.Field(sequential=False,\n","                   use_vocab=False,\n","                   batch_first=False,\n","                   is_target=True,\n","                   dtype=torch.float)\n","\n","\n","from torchtext.data import TabularDataset\n","\n","\n","train_data, test_data = TabularDataset.splits(path='.', train='/content/drive/MyDrive/Colab Notebooks/악플맞춤법_train.csv', test='/content/drive/MyDrive/Colab Notebooks/악플맞춤법_test.csv', format='csv', fields=[('text', TEXT), ('label', LABEL)], skip_header=True)\n","\n","print(vars(train_data[0]),vars(train_data[1])) #0번째 1번째 데이터 출력\n","print(train_data.shape)\n","\n","TEXT.build_vocab(train_data, min_freq=5, max_size=20000) #최대 2만개, 5번 이상 나오는 단어로 단어사전\n","#unk=0, pad=1\n","vocab_size = len(TEXT.vocab)\n","print(vocab_size)\n","train_data, val_data = train_data.split(split_ratio=0.8) #train_data와 val_data에 train_data를 8:2로 나눔\n","\n","train_iter, val_iter, test_iter = data.BucketIterator.splits(\n","    (train_data, val_data, test_data), batch_size=100,\n","    shuffle=True, repeat=False, sort=False) #하나의 이터레이터에 batch_size만큼의 묶음으로 저장\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'text': ['유명', 'a', '씨', '의', '딸', '이', '음주', '뺑소니', '를', '하', '고', '도', '회사', '법무', '팀', '이', '고용', '하', 'ㄴ', '로펌', '의', '끈질기', 'ㄴ', '변호', '덕', '에', '집행유예', '를', '이끌', '어', '내', '었', '습니다', '.', '이건', '우리', '사법', '엑사', '에', '쾌거', '이', 'ㅂ니다', '.', '음주', '뺑소니', '재범', '하', '시', 'ㄴ', '재력가', '들', '은', '억울', '하', '게', '옥', '사리', '하지', '마시', '고', '전화', '주', '시', '어요', '.', '1588', '~', '로펌', '로펌', '.', '판사', '들', '을', '하버드', '출신', '용병', '으로', '대체', '하', '아서', '이해관계', '를', '단절', '시키', '어라', '~', '그', '길', '이', '유일한', '선택', '.', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't'], 'label': '0'} {'text': ['반성', '하', 'ㄴ다고', '집행유예', '이', '라', '…', '진짜', '진짜', '넓', '게', '생각', '하', '아서', '한', '번', '은', '실수', '이', '라', '치', '어도', '심지어', '두', '번', '째', '이', 'ㄴ데요', '…', '?', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't', '\\\\', 't'], 'label': '0'}\n","<generator object Dataset.__getattr__ at 0x7ff8db400308>\n","13481\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8bi6UsWRNAFN","executionInfo":{"status":"ok","timestamp":1607259589706,"user_tz":-540,"elapsed":974,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}}},"source":["######################CNN 모델\n","class CNN(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim,\n","                 dropout, pad_idx):\n","        super().__init__()\n","\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n","\n","        self.convs = nn.ModuleList([\n","            nn.Conv1d(in_channels=embedding_dim,\n","                      out_channels=n_filters,\n","                      kernel_size=fs)\n","            for fs in filter_sizes\n","        ])\n","\n","        self.fc = nn.Linear(len(filter_sizes) * n_filters, output_dim)\n","\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text):\n","        # text = [batch size, sent len]\n","\n","        embedded = self.embedding(text)\n","\n","        # embedded = [batch size, sent len, emb dim]\n","\n","        embedded = embedded.permute(0, 2, 1)\n","\n","        # embedded = [batch size, emb dim, sent len]\n","\n","        conved = [F.selu(conv(embedded)) for conv in self.convs]\n","\n","        # conved_n = [batch size, n_filters, sent len - filter_sizes[n] + 1]\n","\n","        pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conved]\n","\n","        # pooled_n = [batch size, n_filters]\n","\n","        cat = self.dropout(torch.cat(pooled, dim=1))\n","\n","        cnn1 =  torch.sigmoid(cat)\n","\n","        # cat = [batch size, n_filters * len(filter_sizes)]\n","\n","        return self.fc(cnn1)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"YVOfhXGwNGJj","executionInfo":{"status":"ok","timestamp":1607259590221,"user_tz":-540,"elapsed":842,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}}},"source":["def binary_accuracy(preds, y):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","\n","    #round predictions to the closest integer\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float() #convert into float for division\n","    acc = correct.sum() / len(correct)\n","    return acc"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"K77nQZUPNK9h","executionInfo":{"status":"ok","timestamp":1607259591507,"user_tz":-540,"elapsed":973,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}}},"source":["def accuracy(probs, target):\n","  predictions = probs.argmax(dim=1)\n","  corrects = (predictions == target)\n","  accuracy = corrects.sum().float() / float(target.size(0))\n","  return accuracy\n"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"fe7pnS1GNNYx","executionInfo":{"status":"ok","timestamp":1607259593000,"user_tz":-540,"elapsed":504,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}}},"source":["import time\n","\n","def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n","    return elapsed_mins, elapsed_secs"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rPQdP4P3yDcu","executionInfo":{"status":"ok","timestamp":1607259594411,"user_tz":-540,"elapsed":826,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}},"outputId":"e8e2f3c6-4457-4b5a-b2c5-c62bfbe72957"},"source":["import torch \n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FHeilJd2NP1d","executionInfo":{"status":"ok","timestamp":1607259595517,"user_tz":-540,"elapsed":600,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}}},"source":["def evaluate(model, iterator, criterion):\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for batch in iterator:\n","            predictions = model(batch.text).squeeze(1)\n","\n","            loss = criterion(predictions, batch.label)\n","\n","            acc = binary_accuracy(predictions, batch.label)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"KaeC47FZNQ5t","executionInfo":{"status":"ok","timestamp":1607259596889,"user_tz":-540,"elapsed":687,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}}},"source":["def train(model, iterator, optimizer, criterion):\n","    epoch_loss = 0\n","    epoch_acc = 0\n","\n","    model.train()\n","\n","    for batch in iterator:\n","        optimizer.zero_grad()\n","\n","        predictions = model(batch.text).squeeze(1)\n","\n","        loss = criterion(predictions, batch.label)\n","\n","        acc = binary_accuracy(predictions, batch.label)\n","\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","\n","    return epoch_loss / len(iterator), epoch_acc / len(iterator)"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"CkI713zkNSXT","executionInfo":{"status":"ok","timestamp":1607259600883,"user_tz":-540,"elapsed":763,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}}},"source":["import torch\n","import os\n","INPUT_DIM = len(TEXT.vocab)\n","EMBEDDING_DIM = 100\n","N_FILTERS = 50\n","FILTER_SIZES = [2,3,4,5,6,7,8,9]\n","#FILTER_SIZES = [2,3,4]\n","OUTPUT_DIM = 1\n","DROPOUT = 0.8\n","PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n","\n","###\n","# EMBEDDING_DIM = 100\n","# N_FILTERS = 100\n","# FILTER_SIZES = [3,4,5]\n","# OUTPUT_DIM = 1\n","\n","model = CNN(INPUT_DIM, EMBEDDING_DIM, N_FILTERS, FILTER_SIZES, OUTPUT_DIM, DROPOUT, PAD_IDX)\n"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xDBW0-VA7lhH","executionInfo":{"status":"ok","timestamp":1607259601194,"user_tz":-540,"elapsed":474,"user":{"displayName":"허다은","photoUrl":"","userId":"17505651751001608524"}},"outputId":"23f2070c-5882-46ef-e636-b475d03f6388"},"source":["model.convs\n","model"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CNN(\n","  (embedding): Embedding(13481, 100, padding_idx=1)\n","  (convs): ModuleList(\n","    (0): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n","    (1): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n","    (2): Conv1d(100, 50, kernel_size=(4,), stride=(1,))\n","    (3): Conv1d(100, 50, kernel_size=(5,), stride=(1,))\n","    (4): Conv1d(100, 50, kernel_size=(6,), stride=(1,))\n","    (5): Conv1d(100, 50, kernel_size=(7,), stride=(1,))\n","    (6): Conv1d(100, 50, kernel_size=(8,), stride=(1,))\n","    (7): Conv1d(100, 50, kernel_size=(9,), stride=(1,))\n","  )\n","  (fc): Linear(in_features=400, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.8, inplace=False)\n",")"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n0YcrJ8iNVUN","outputId":"6614462c-266d-47b6-d131-fbce6a7551f4"},"source":["if __name__ == \"__main__\":\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    print(device)\n","    model_type = \"CNN\"  # or: \"token\"\n","\n","    data_type = \"morph\"  # or: \"token\"\n","\n","    criterion = nn.BCEWithLogitsLoss()\n","    optimizer = torch.optim.Adam(model.parameters(), lr=0.003) #경사하강법 Adam\n","    N_EPOCHS = 15\n","\n","    best_valid_loss = float('inf')\n","\n","    for epoch in range(N_EPOCHS):\n","\n","        start_time = time.time()\n","        train_loss, train_acc = train(model, train_iter, optimizer, criterion)\n","        valid_loss, valid_acc = evaluate(model, val_iter, criterion)\n","\n","        end_time = time.time()\n","\n","        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n","\n","        if valid_loss < best_valid_loss:\n","            best_valid_loss = valid_loss\n","            torch.save(model.state_dict(), 'tut4-model.pt')\n","\n","        print(f'Epoch: {epoch + 1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%')\n","        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc * 100:.2f}%')\n","\n","model.load_state_dict(torch.load('tut4-model.pt'))\n","\n","test_loss, test_acc = evaluate(model, test_iter, criterion)\n","\n","print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["cuda\n","Epoch: 01 | Epoch Time: 2m 15s\n","\tTrain Loss: 0.562 | Train Acc: 79.20%\n","\t Val. Loss: 1.915 |  Val. Acc: 79.22%\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PMvuHM7vdYVt"},"source":["from torchtext import data\n","\n","tokenizer = Komoran()\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(device)\n","def predict_sentiment(model, sentence, min_len = 60):\n","    model.eval().to(device)\n","    tokenized = [tok for tok in tokenizer.morphs(sentence)]\n","    print(tokenized)\n","    if len(tokenized) < min_len:\n","        tokenized += ['<pad>'] * (min_len - len(tokenized))\n","    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n","    length = [len(indexed)]\n","    tensor = torch.LongTensor(indexed).to(device)\n","    tensor = tensor.unsqueeze(0)\n","    length_tensor = torch.LongTensor(length)\n","    prediction = torch.sigmoid(model(tensor))\n","    return prediction.item()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-p_ZoNada4f"},"source":["predict_sentiment(model, \"뀨\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kjpby_H3NulO"},"source":["# !nvcc --version"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHw-THz3OC54"},"source":["# pip install torch==1.7.0+cu101 torchvision==0.8.1+cu101 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html"],"execution_count":null,"outputs":[]}]}